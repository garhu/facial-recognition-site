<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Arrested For Someone Else's Face</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
				<div id="intro">
					<h1>Arrested For<br/>Someone Else's Face
					</h1>
					<p>Dangerously flawed facial recognition systems are becoming alarmingly pervasive within law enforcement.</p>
					<ul class="actions">
						<li><a href="#main" class="icon solid solo fa-arrow-down scrolly"></a></li>
					</ul>
				</div>

				<!-- Main -->
				<div id="main">

					<!-- Featured Post -->
					<article class="post featured">
						<header class="major">
							<div class ="content-stuff">
								<p id="author"><b>By Gary Hu</b></p>
								<p class="date">December 8, 2021</p>
								<p>On a Thursday afternoon in January 2020, Robert Julian-Borchak Williams drove back from work to his home in Farmington
								Hills, Michigan. When he pulled into his driveway, a police car immediately blocked him in and he was subsequently
								arrested on his lawn in front of his wife and two daughters. Police refused to disclose what he was being arrested for.
								Instead, he was only shown a piece of paper with his photo and the words “felony warrant” and “larceny.”</p>
							</div>
						</header>
							<div class="image-div">
								<img src="images/family.jpeg">
								<p>Robert Julian-Borchak Williams pictured with his wife and two daughters.</p>
							</div>
						<header class="major">
							<div class="content-stuff">
								<p>Detroit police were conducting an investigation on who stole five watches from a Shinola retail store - an estimated
								$3,800 worth of merchandise. Mr. Williams was led into an interrogation room, where he was shown an image from a
								surveillance video showing a “heavyset man, dressed in black and wearing a red St. Louis Cardinals cap, standing in
								front of a watch display,” according to a New York Times article. A blurry close-up from this image was also presented
								to him which was clearly not Mr. Williams. In response, he put the photo next to his face and said, “You think all black
								men look alike?”</p>
								<p>What Mr. Williams didn’t know was that he was the first known account of an American being wrongfully arrested based on
								a flawed match from a facial recognition algorithm.</p>
								<p>The use of facial recognition systems in law enforcement has become widespread across the United States in recent years.
								A study from Georgetown Law's Center on Privacy and Technology shows that at least a quarter of all American state and
								local law enforcement agencies “can run face recognition searches of their own databases, run those searches on another
								agency’s face recognition system, or have the option to access such a system.” With technology of this magnitude, the
								legislation has failed to keep up - leaving investigators with little restrictions when handling facial recognition to
								make arrests. This ultimately puts millions of Americans at risk of being arrested off of a flawed face match.</p>
								<p>One of the most important issues with the lack of regulations is that it further perpetuates the tension between
								minorities and the criminal justice system. According to research from Pew Research Center, there is an 18% difference
								in the number of black Americans that trust facial recognition used by law enforcement compared to white Americans.</p>
								<p>This skepticism isn’t baseless. The National Institute of Standards and Technology conducted a study of over 100 facial
								recognition systems and found that a majority of commercial facial-recognition systems exhibit bias due to a lack of
								diversity in the images used to develop the underlying algorithms. DataWorks Plus, the software used to identify Mr.
								Williams, was found to have falsely identified African-American and Asian faces 10 times to 100 times more than
								Caucasian faces.</p>
								<p>Inputting blurry photos into the system further exacerbates potential biases. DataWorks tests their systems by running
								searches using low-quality images of individuals it knows are present in a system; however, DataWorks does not formally
								measure the systems’ accuracy or bias - leaving investigators with no information on how reliable the system may be.</p>
								<p>While legislation has remained stagnant, experts have been developing solutions to address this issue. Dr. Richardson of
								Northeastern University categorized these solutions into three groups: transparency requirements, use requirements, and
								oversight mechanisms. These solutions would ultimately prevent the misuse of facial recognition technology.</p>
								<p>The requirement for transparency is the mandate of regular, public reporting of the technology’s use by the government.
								In addition, facial recognition systems would have to be made available to the public for independent review and be open
								to challenge from the community. These requirements equip the public with information regarding the use of facial
								recognition technology and enables citizens to provide accountability for the technology’s use within law enforcement
								agencies.</p>
								<p>Had the software from DataWorks been public, independent reviewers would have been able to formally determine the
								accuracy and bias of the system when using low-quality images, like the one in Mr. Williams’s case. Preventative
								measures could have then been taken to forbid the blurry close-up from being used as an input to the system.</p>
								<p>Use requirements would include police training on how to make facial recognition comparisons. Under this training,
								police would learn to understand what photographs could be considered as valid inputs of the facial recognition system.
								This is critical to maximize accuracy and minimize bias when using the technology. Use requirements would also
								necessitate a statement of the crime and a factual narrative to demonstrate that the suspect is connected to the crime
								before facial recognition software can be used.</p>
							</div>
						</header>
						<div class="image-div">
							<img src="images/side-by-side.png">
							<p>Michigan State Police investigative lead report used to arrest Robert Julian-Borchak Williams.</p>
						</div>
							<header class="major">
								<div class="content-stuff">
								<p>Despite the emphasized warning on the police document, the document was ultimately used as the only source of evidence
								for the arrest. Investigators did not seek out other evidence such as eyewitness testimony, location data from his
								phone, or proof that he owned the clothing that the suspect was wearing.</p>
								<p>On the night that the shoplifting occurred, Mr. Williams was driving home from work, and had posted a video of himself
								to his private Instagram. Had the police checked for this information during the investigation, they would have found
								Mr. Williams to be innocent.</p>
								<p>Oversight mechanisms would entail imposing review procedures for facial recognition throughout the deployment of the
								facial recognition in a case. This would include practicing double-blind confirmation where a connection using facial
								recognition would only be valid when two analysts independently conclude that the images are a possible match.</p>
								<p>Maria Miller, a spokeswoman for Mr. Williams, said a second witness was at the store when the shoplifting occurred, but
								was not asked to look at the photo lineup.</p>
								<p>These solutions would effectively prevent false arrests based on a flawed facial recognition match through the
								requirement of extensive precautionary measures when using the technology. Facial recognition can be an extremely
								valuable tool when used correctly and these solutions intend to maximize the technology’s potential while addressing the
								root issues that lead to its misuse.</p>
								<p>By allowing police to identify racial biases when using this technology and by allowing community members to hold law
								enforcement agencies accountable, the outlined solutions would be able to rebuild trust between minority communities and
								law enforcement.</p>
								<p>Mr. Williams became the first of many people to be wrongfully arrested due to facial recognition algorithms. The
								technology is quickly growing and without regulations, the potential for harm will continue to increase everyday.</p>
							</div>
						</header>
					</article>

				</div>




		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>


	</body>
</html>